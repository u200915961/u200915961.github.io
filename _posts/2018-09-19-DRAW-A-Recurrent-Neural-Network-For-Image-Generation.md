---
layout: post
title: 'DRAW: A Recurrent Neural Network For Image Generation'
subtitle: '基于注意力机制的图像迭代生成'
date: 2018-09-19
categories: paper
cover: 'http://pics.qiangbenyk.cn/2018_09_19_18_47_15_465-V.png'
tags: architecture deeplearning Attention
---

# DRAW: A Recurrent Neural Network For Image Generation

> from ICML 2015

本文提出一种基于注意力机制的图像迭代生成模型，作者将图像生成过程看成是时序演变过程，引入注意力机制，每个时序只绘制其中一个部分。

## 动机

传统的图像生成过程是单阶段的，如自编码器`AE`,变分自编码器`VAE`，都是通过一个随机变量生成一张有意义的图像。这种方式在构建大规模场景图像时，难度很大。联想人类绘图方式，常见两种绘图方式：

1. 将整个图像划分为多个部分，逐步构建出整张图像。如人体素描。

   ![](http://pics.qiangbenyk.cn/2018_09_19_19_07_05_223-H.png)

2. 总整体轮廓开始，逐步丰富细节。如简笔画。

   ![](http://pics.qiangbenyk.cn/2018_09_19_18_53_27_730-T.png)

是否可以模仿这种方式实现图像生成任务？针对第一种方式，有了本文的`DRAW`模型，针对第二种方法，有了本文不使用注意力机制的`DRAW`和`Laplacian GAN`。

## 方法

本文收第一种方式启发，提出深层循环注意力绘制的结构，模仿人类每次绘制一个部分的方法，将图像绘制看成是一个时序演变过程，每次绘制图像的一个部分，逐步对图像进行精修。

本文提出的`DRAW`结构和变分自编码器类似。但还是有一些明显区别的：

1. `DRAW`的编码器和解码器都是循环网络
2. `DRAW`编码器的输出是逐步添加到某个分布中的，最后才生成整个数据。
3. `DRAW`在编码器和解码器中都引入了动态更新的注意力机制。网络决定每一个时序应该从图像中读取哪个部分，以及绘制哪个部分。**该注意力机制完全可导，可以使用BP算法训练。**



网络结构：

![](http://pics.qiangbenyk.cn/2018_09_19_18_47_15_465-V.png)

> 左图为传统变分自编码器，右图为本文提出的`DRAW`结构。

`DRAW`的编码器和解码器可以使用任何循环神经网络实现，本文使用了`LSTM`网络结构，因为这种模型可以处理较长时间间隔的序列数据。在每一个时间序列，编码器输入源图像以及上一个时序解码器的隐变量。

和变分自编码器类似，本文将图像的潜在分布看作高斯分布$Z_t \sim N(u_t,\sigma_t)$。

![](http://pics.qiangbenyk.cn/2018_09_19_19_36_51_354-a.png)

其中$h_t^{enc}$为编码器的输出，用来参数化潜在分布的后验分布。式中$b=W(a)$表示代偏置量的全连接层。

模型的时序长度$T$需要提前制定。

整个模型的运算过程如下：($t=1,2,…,T$)

![](http://pics.qiangbenyk.cn/2018_09_19_19_44_53_933-u.png)

对式中标记做简单说明

1. $x$表示输入图像

2. $\sigma$是sigmoid激活函数
3. $\hat x_t$表示错误图像
4. $read()$表示图像读取函数，基于注意力机制读取原始图像的一个部分
5. $[v,w]$表示通道合并操作，将$v$和$w$合并为一个向量
6. $RNN^{enc}$表示编码循环网络
7. $h_{t}^{enc}$表示第$t$层编码器隐变量
8. $Q$表示以$h_{t}^{enc}$为参数的潜在变量分布
9. $z_t$表示从$Q$中采样的潜在变量随机向量
10. $RNN^{dec}$表示解码循环网络
11. $h_{t}^{dec}$表示第$t$层解码器隐变量
12. $write()$表示图像绘制函数，，基于注意力机制生成图像的一个部分
13. $c_t$表示第$t$个时序生成的图像

模型的损失函数有两个部分，分别为重建损失和潜在变量先验分布和后验分布的KL散度损失：

- 重建损失：

  ![](http://pics.qiangbenyk.cn/2018_09_19_20_00_51_863-B.png)

- KL散度损失：

  ![](http://pics.qiangbenyk.cn/2018_09_19_20_01_23_034-z.png)

  ![](http://pics.qiangbenyk.cn/2018_09_19_20_03_19_917-a.png)


图像生成流程：

![](http://pics.qiangbenyk.cn/2018_09_19_20_10_04_535-P.png)

-----------------------------------

**下面详细介绍`DRAW`中的$read()$和$write()$方法，以及`Attention`机制**

$read()$方法用来告诉模型，当前时序需要学习源图像中的哪部分内容。

$write()$方法用来告诉模型，当前时序需要绘制生成图像的哪部分内容。

### 无注意力方法

无注意力方法比较简单，直接对整张图片获取特征，并依据特征重建整张图像。

![](http://pics.qiangbenyk.cn/2018_09_19_21_52_37_722-J.png)

### 注意力方法

本文使用一个2维形式表示注意力，对一张图像使用2D高斯滤波，产生一个图像块。

具体流程如下：

1. 确定高斯核的尺寸，假设为$N\times N$；确定高斯核元素之间的间距，假设为$\delta$；确定高斯核中心坐标$(g_X,g_Y)$

   ![](http://pics.qiangbenyk.cn/2018_09_19_21_13_04_247-T.png)

2. 通过上述参数可以确定图像块每个位置的像素值，其中$\delta$越大，图像块包含的源图像区域越大，但是patch的分辨率越小。图像块中第$i$行$j$列的值与源图像中第$X$行$Y$列的对应关系为：

   ![](http://pics.qiangbenyk.cn/2018_09_19_20_44_42_858-H.png)

   下图分别表示$\delta=1$和$\delta=2$时，图像块中的内容。

   ![](http://pics.qiangbenyk.cn/2018_09_19_20_42_23_812-u.png)

3. 另外还需要两个参数：高斯分布的各向异性方差$\sigma^2$和尺度强度$\gamma$

给定大小为$A\times B$的图像$x$，上述五个注意力参数都是根据每个时序中解码器的隐变量决定的。隐变量经过一个全连接层，输出5个注意力参数。再由五个参数计算得到图像块中心和高斯算子的间距$\delta$.

![](http://pics.qiangbenyk.cn/2018_09_19_20_52_05_619-B.png)

另外，定义两个矩阵，论文中说是表示*horizontal and vertical filterbank matrices*，分别表示为$F_X,F_Y$，形状分别为$N\times A$和$N\times B$，详细表达不理解。

![](http://pics.qiangbenyk.cn/2018_09_19_21_40_16_883-N.png)

个人认为，通过这两个矩阵和源图像做乘法，可以得到上述参数定义的注意力区域的图像块。

$read()$方法定义为：

![](http://pics.qiangbenyk.cn/2018_09_19_21_43_03_419-J.png)

计算公式内的三个矩阵连乘，可以得到一个$N\times N$的矩阵，和图像块大小一致，这里个人理解表示一种获取图像块的方式。

$write()$方法定义为：

![](http://pics.qiangbenyk.cn/2018_09_19_21_43_49_921-V.png)

公式内执行了与$read()$方法相反的矩阵连乘，获得尺寸为$A\times B$的矩阵，和输入图像大小一致，个人推测，这里$w_t$表示对图像块的重建，通过$write()$方法执行获取图像块的反变换，恢复图像块在原图中的位置。

## 实验

1. 通过时间序列逐步生成手写体数字

   ![](http://pics.qiangbenyk.cn/2018_09_19_21_48_18_132-I.png)

2. 带噪声的手写体识别任务

   ![](http://pics.qiangbenyk.cn/2018_09_19_21_49_34_573-C.png)

3. 不使用注意力机制的手写体生成

   ![](http://pics.qiangbenyk.cn/2018_09_19_21_50_37_240-E.png)