---
layout: post
title: 'Recurrent Models of Visual Attention'
subtitle: '将图像特征看作是注意力轨迹序列特征'
date: 2018-09-17
categories: paper
cover: 'http://pics.qiangbenyk.cn/2018_09_17_16_28_18_862-1.png'
tags: Attention deeplearning 
---

# Recurrent Models of Visual Attention

> from NIPS 2014

这算是一篇比较老的文章，但是想法比较有趣，这里做一个简单的整理。

## 动机

卷积网络在图像分类，目标检测，语意分割等各个方面成效显著。但是，卷积网络有一个问题，网络的计算量随着输入图像的尺寸的增加线性增加。而图像中通常有很大一部分区域对特定任务是没有作用的，甚至对结果的判断有烦作用。

![](http://pics.qiangbenyk.cn/2018_09_17_16_58_22_062-Y.png)

如图所示，人类在观察图象时，通常只对几块关键区域感兴趣，比如图上的猴子，人们可能先观察到树木，再根据树枝的走向找到树干上的猴子，这种现象在大规模场景中的小目标检测尤为明显。

## 方法

本文提出一种任务驱动的基于注意力的网络模型，模型模拟人眼观察图像顺序，将观察子区域整个过程看成时间序列，根据该序列做出判断。

![](http://pics.qiangbenyk.cn/2018_09_17_16_28_18_862-1.png)

模型分为三个子模块：

1. **Glimpse Sensor** 视觉传感器，可以看作是一个视窗。该模块输入当前视窗的中心坐标以及原始图像，以该坐标为中心采集若干张不同分辨率的patch，通过网络生成该位置图像信息的特征表示。
2. **Glimpse Network** 视觉网络，用来对位置信息和该位置图像信息的特征表示。该模块输入当前视窗中心以及原始图像，经过`Glimpse Sensor`生成该位置图像的特征表示，再分别使用各自的映射层将位置信息和该位置的图像信息映射到隐空间，再使用另一个映射层将组合前面生成的两个隐空间特征。
3. **Model Architecture** 整个模型本质上是一个`RNN`，将每次视窗中心移动的结果作为`RNN`的一个时间步。将`Glimpse Network`的输出以及前一个隐状态作为`RNN`的输入，产生新的隐变量，在以隐变量为参数生成分别服从两种分布的变量，分别表示状态奖励和位置移动。下一次移动取决于上一个隐状态和当前任务。

该模型可以使用强化学习进行优化。

如果样本有标签，可以使用监督学习，令状态奖励视作预测值，可以使用BP算法做优化，但是，位置移动变量没有梯度，因此只能通过强化学习优化。