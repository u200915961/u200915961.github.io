---
layout: post
title: 'Spatial Transformer Networks'
subtitle: '空间变换网络'
date: 2018-09-18
categories: paper
cover: 'http://pics.qiangbenyk.cn/2018_09_18_15_23_48_697-5.png'
tags: architecture deeplearning Attention
---

# Spatial Transformer Networks

>from NIPS 2015

这篇文章介绍了一种通用的网络结构，可以直接应用到现有的各种卷积网络中，提升学习到的特征的不变性。

## 动机

卷积网络在应对视觉任务时，经常会因为图像中目标的姿态，尺寸等因素影响最后的判断。尽管CNN模型中有`Pooling`操作，可以带来一定的不变性，但是这不足以适应变化较大的图像。

> 可以考虑用图像增强方式提升特征不变性，但是模拟出所有可能的变换不太实际。

## 方法

本文提出一种空间变换模块，可以应用到标准网络结构中，为其提供空间变换能力，并且这种空间变换完全是根据输入而定的，因此会根据输入执行特定的空间变换。变换操作在整个特征图上执行，包括缩放，裁剪，旋转，非刚性形变等操作。通过这些操作，可以让卷积网络选择最相关的区域，并且将该区域的目标转换到一个适当的姿态。空间变换模块可以使用BP算法优化。

空间变换模块可以应用到多种任务中：

1. **图像分类**

   对于手写体识别任务，使用空间变换模块可以裁剪出数字区域，并且缩放到一个特定尺寸，这样可以提升分类性能。

   ![](http://pics.qiangbenyk.cn/2018_09_18_16_00_43_534-O.png)

   图中(a)列表示输入图像，数字的大小，位置，方向都不一致；(b)列是空间变换模块应用到图像上的变换；(c)列是空间变换模块的输出；(d)列是分类结果

2. **目标定位**

   给定一组含有一类别不同对象的图像，空间变换模块可以用来定位图像中的目标

3. **空间注意力**

   空间变换模块可以用来获得注意力机制。注意力的关键优势是，利用变换后的或者被关注的低分辨率输入可以用来替代原始的高分辨输入，提升运算效率。

-------------------------

空间变换模块的结构：

![](http://pics.qiangbenyk.cn/2018_09_18_15_23_48_697-5.png)

空间变换模块可以分为三个：

1. **Localisation Network** 定位网络，用于生成定位变换的参数

   定位网络是用来做参数回归的，可以是任何形式的，比如全连接网络或者卷及网络，只要最后的数目和类型与变换参数一致就可以。

   定位网络输入尺寸为[w,h,c]的特征图，分别表示图像的宽度，高度和通道数目，生成输出变换参数$\theta$，输出的形状由变换类型决定，对于仿射变换，输出为6维向量。

2. **Parameterised Sampling Grid** 参数化采样网格，基于变换参数，生成变换后索引网格

   执行变换后，源图像中对应像素的位置会产生变化，假设由定位网络产生的参数为2D仿射变换，则坐标变换可以用下面公式表示

   ![](http://pics.qiangbenyk.cn/2018_09_18_16_38_49_310-h.png)

   其中$\begin{pmatrix}x_i^t \\ y_i^t \end{pmatrix}$ 表示图像第$i$个像素的原始坐标，$A_\theta$表示变换矩阵，一共有6个参数，$\begin{pmatrix}x_i^s \\ y_i^s \end{pmatrix}$是第$i$个像素变换后的坐标。

   ![](http://pics.qiangbenyk.cn/2018_09_18_16_50_55_610-S.png)

   变换的形式可以可以自定义的，比如可以使用8个参数的平面投影变换，或者对其中部分参数加以限制，控制变换的自由度。

   ![](http://pics.qiangbenyk.cn/2018_09_18_16_53_08_100-C.png)

   如果定义为这种形式，表示了一种有修剪，平移和缩放能力的注意力机制。

   参数化采样网格有两个输入，分别是变换参数$\theta$和原始图像的像素索引，生成新图像的像素索引。

3. **Differentiable Image Sampling** 可导的图像采样器，基于变换后的索引网格，生成变换后的图像

   根据采样网格生成的新索引，可以获取变换后的图像。该模块是可导的，因此可以用BP算法进行优化。具体运算过程如下：

   ![](http://pics.qiangbenyk.cn/2018_09_18_17_04_09_229-C.png)

   其中$V_i^c$表示变换后图像中第$c$个通道内第$i$个像素在特征图上的值，$\Phi_x$和$\Phi_y$表示采样核$k()$的参数，定义了图像的插值方法，$U_{nm}^c$表示输入图像在第$c$个通道上$(n,m)$的值。采样是通道和输入独立的，所以每个通道上的变换都是独立的。

   理论上来说$k()$可以是任意一种采样核，只要能在$x_i^s$和$y_i^s$上定义梯度。可以使用最近邻插值或者B样条插值。

   为了让采样机制能支持反向传播，本文定义了关于输入图像$U$和采采样网格$G​$的梯度，以B样条插值为例：

   ![](http://pics.qiangbenyk.cn/2018_09_18_17_21_57_175-2.png)

## 总结

**Spatial Transformer Networks** 能够在没有标注关键点的情况下，根据任务自己学习图片或特征的空间变换参数，将输入图片或者学习的特征在空间上进行对齐，从而减少物体由于空间中的旋转、平移、尺度、扭曲等几何变换对分类、定位等任务的影响。加入到已有的CNN或者FCN网络，能够提升网络的学习能力。