---
layout: post
title: 'Attention to Scale: Scale-aware Semantic Image Segmentation'
subtitle: '基于不同尺度注意力的图像分割方法'
date: 2018-09-20
categories: paper
cover: 'http://pics.qiangbenyk.cn/2018_09_20_12_41_31_268-U.png'
tags: architecture deeplearning Attention
---

# Attention to Scale: Scale-aware Semantic Image Segmentation

> from CVPR 2016

本文是提出一种新颖的注意力框架，在不同尺度的特征图中引入注意力，从而提升特征的判别能力。这充分说明，注意力机制不仅仅可以用在序列分析，空间位置这两个方面，可以有更广阔的使用范围。

## 动机

先前有很多基于图像注意力的工作，主要集中在图像文本描述生成，图像问答，图像分类，目标检测等。注意力的类型可以总结为两大类：

1. 基于时间序列的注意力机制，主要用于对序列中不同时间的信息做加权
2. 基于空间位置的注意力机制，主要用于对图像中不同位置的信息做加权

现在视觉任务大多融入多尺度特征，不同尺度下的特征图对最后的结果是否起到相同的影响？

本文将注意力引入到多尺度特征中，对不同尺度下的特征加权，从而可以判断不同尺度下不同位置的特征对结果判断的重要性。

## 方法

本文主要解决图像分割任务。多尺度特征在图像分割任务上相当普遍的应用，现阶段主要有两种手段引入多尺度:

1. **skip-net** 即通过池化层，生成多个不同尺度的特征图，再通过skip-connect建立多尺度特征之间的联系，最终生成分割结果。

   ![](http://pics.qiangbenyk.cn/2018_09_20_13_23_45_446-e.png)

2. **share-net** 即将图像缩放到不同尺寸，中间使用共享参数的网络层提取图像特征，最终生成分割结果。本文使用这种结构。

   ![](http://pics.qiangbenyk.cn/2018_09_20_13_24_25_743-C.png)

本文使用DeepLab模型作为本文的基础架构，再将本文提出的多尺度注意力模块引入DeepLab。不同尺度间的**average pooling**和**max pooling**可以看成是本文提出的多尺度注意力模型的特例。

接下来详细介绍本文提出的多尺度注意力模型。

给定一张输入图像$x$,首先将图像缩放到多个不同尺寸$s=1,2,3…S$，将每一个尺寸的图像输入到DeepLab网络中(共享权值)，产生$s$个对应的得分图,使用$f_{i,c}^s$表示，其中$s$表示产生的s个得分图，$i$表示输入图像的所有像素点序号(比如源图像为$20\times 20$，$i$的范围是0~399),$c$表示类别的序号，所有的得分图都缩放到相同尺寸。定义加权后的得分图为$g_{i,c}^s​$，如果权值取1/S，则可以看成是多尺度特征间的average-pooling;如果求和改成求最大值，则可以看成多尺度特征间的max-pooling，因此本文的注意力模型可以看成是这两种池化操作的一般化。

![](http://pics.qiangbenyk.cn/2018_09_20_13_41_13_113-e.png)

![](http://pics.qiangbenyk.cn/2018_09_20_13_50_00_138-h.png)

其中$W_i^s$为注意力,在所有通道共享：

![](http://pics.qiangbenyk.cn/2018_09_20_13_42_09_246-i.png)

![](http://pics.qiangbenyk.cn/2018_09_20_13_50_27_356-b.png)

$h_i^s$表示**softmax**层前一层的第$i$个像素在尺度$s$下的值。注意力模型的输入是另一个VGG-16网络卷积核后的`fc7`层的特征，如上图，该网络层有两个卷积层，第一个卷积核数目为512,尺寸为$3\times 3$，第二个卷积核数目为$S$，卷积核尺寸为$1\times 1$。

整个网络结构图：

![](http://pics.qiangbenyk.cn/2018_09_20_12_41_31_268-U.png)

本文将额外的监督也引入到模型中，对所有尺度下的分割结果做监督，可以提升合并后特征的判别能力，进而提升分割性能。

## 实验

细粒度图像分割

![](http://pics.qiangbenyk.cn/2018_09_20_15_07_14_304-Z.png)

可以看出，在不同尺度下，模型关注的区域是不一样的。

