---
layout: post
title: 'Show, Attend and Tell: Neural Image Caption Generation with Visual Attention'
subtitle: '利用注意力机制实现图像描述生成'
date: 2018-09-14
categories: paper
cover: 'http://pics.qiangbenyk.cn/2018_09_14_10_55_51_587-A.png'
tags: Attention object_location deeplearning Image_Caption
---

# Show, Attend and Tell: Neural Image Caption Generation with Visual Attention

## 动机

给定一张图像，自动生成对该图像的描述，这是一个比较困难的问题。如下图，人类可以很容易地描述下面图像:“三个小孩在夕阳下放风筝”。模型不仅仅需要知道图像中的目标，而且需要理解目标之间的相互关系。目前有两大类图像描述方法，一种是生成图像描述的模板，使用目标检测或者属性探索的方法对模板做填充；另一种首先从大型数据库检索类似的标题图像，然后修改这些检索的标题。传统方法都是使用卷积网络提取图像的高层特征，这些特征通常只关注图像中最显著的区域，可能会丢失一些有用的信息。使用浅层特征可以保留这部分信息。

![](http://pics.qiangbenyk.cn/2018_09_14_10_57_47_261-x.png)

## 方法

本文将注意力机制引入图像描述任务，提出下面的网络结构，在图像描述任务上取得不错的效果。

![](http://pics.qiangbenyk.cn/2018_09_14_11_42_24_808-j.png)

- 模型结构

  本文提出的模型输入一张图像，并且生成对应的文本描述，输出的文本描述用$y$表示，$y$是由一组$K$维词向量构成的序列:

  ![](http://pics.qiangbenyk.cn/2018_09_14_13_21_06_931-G.png)

  其中$K$表示词向量的维度，$C$表示生成序列的长度。

  模型有两个部分组成，一个是卷积网络构成的编码器，用来提取图像特征；另一个是LSTM构成的解码器，用来生成文本描述。

  - 编码器

    编码器就是一个没有全连接层的卷积网络，用来提取$L$个特征，这里用$a$表示，每一个特征都是一个$D$维向量，分别表示图像中的一个对应区域。

    ![](http://pics.qiangbenyk.cn/2018_09_14_13_24_48_220-G.png)

  - 解码器

    本文使用`LSTM`(长短时记忆网络)作为解码器，`LSTM`是一种常用的循环神经网络，适合对序列数据进行建模，本文使用的解码器结构如下：

    ![](http://pics.qiangbenyk.cn/2018_09_14_13_26_58_092-T.png)

    详细的推导过程：

    ![](http://pics.qiangbenyk.cn/2018_09_14_13_36_23_879-E.png)

    下面对各个变量做解释：

    | 变量  |   解释   |
    | :---: | :------: |
    | $i_t$ |  输入门  |
    | $f_t$ |  遗忘门  |
    | $c_t$ | 记忆单元 |
    | $o_t$ |  输出门  |
    | $h_t$ | 隐藏状态 |
    |  $W$  | 权重矩阵 |
    |  $U$  | 权重矩阵 |
    |  $Z$  | 权重矩阵 |
    |  $b$  |  偏置量  |
    |  $E$  | 嵌入矩阵 |
    |  $\sigma$   | sigmoid函数 |

    具体流程如下：

    现有一张图像$I$，使用编码器对图像$I$提取特征$a$，长度为$L$，每个子区域特征用$a_i$表示。定义一个函数$\phi$可以通过$a$计算出$\hat z_t$，表示$t$时刻图像对应区域的表示，也可以理解为生成某个词时对应的子区域的特征表示。每一个位置$i$，$\phi$都会产生一个正值权重$\alpha _i$，可以理解为该区域产生下一个关键词的概率，或者该区域的重要程度。每一个子区域特征$a_i$的权重$\alpha _i$都是通过注意力模型$f_{att}$根据前一个隐藏状态$h_{t-1}$计算的，本文使用一个多层感知机实现注意力模型。隐藏状态会随着输出的陆续生成而变化，也就是说网络接下来要看什么地方，取决于已经生成的文本。权值计算完，就可以得到对应区域的向量表示$\hat z_t$。

    ![](http://pics.qiangbenyk.cn/2018_09_14_13_59_39_650-x.png)

    ![](http://pics.qiangbenyk.cn/2018_09_14_14_08_03_121-t.png)

- 两种注意力机制

  文章提出两种注意力机制`soft deterministic attention mechanism`以及`hard stochastic attention mechanism`。

  - **Stochastic “Hard” Attention**

    > 该方法基于强化学习，由于对强化学习并不了解，只能对文章做简单翻译。

    作者用一个矩阵$s$表示作为定位信息的存储变量，$s_t$表示模型产生第$t$个词汇时关注的位置，$s_t$是一个one-hot类型的指示向量，长度为$L$，即子区域的数目，如果$t$生成词汇时使用了第$i$个子区域的特征，则$s_{t,i}$的值为1。可以将注意力位置看成是一个隐变量，并且服从以$\alpha_I$为参数的多项式分布，所以也可以将$\hat z_t$看作一个随机变量：

    ![](http://pics.qiangbenyk.cn/2018_09_14_14_27_04_161-T.png)

    回到之前，原始问题可以描述为$p(y | a)$，即给定图像，给出正确图像描述的概率。作者定义了一个新的目标函数$L_s$，该目标函数就是原始问题边缘对数似然函数的变分下界。模型参数的学习算法可以通过下面的优化算法直接推算：

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_09_04_799-G.png)

    目标函数$L_s$的梯度：

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_11_05_904-v.png)

    可以用蒙特卡洛法估算目标函数的梯度:

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_12_16_659-X.png)

    其中$\widetilde s^n=(s_1^n,s_2^n,…)$是一个采样的注意力位置，使用多项式分布采样：

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_14_42_713-f.png)

    本文使用移动平均基线技术降低方差。

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_20_46_230-v.png)

    为进一步降低方差，估算的目标函数后增加多项式分布熵$H[s]$的梯度，如下图公式，其中$\lambda_{\gamma} $和$\lambda_e$为交叉验证的超参。

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_23_41_748-f.png)

    该公式和强化学习方法一致。

    为了进一步提升学习规则的鲁棒性，作者以0.5的概率将采样点注意力位置$\widetilde s$设置为$\alpha$

  - **Deterministic “Soft” Attention**

    上述方法每次都需要对注意力位置指示矩阵$s_t$进行采样，也可以直接使用上文提到的区域特征$\hat z_t$的期望:

    ![](http://pics.qiangbenyk.cn/2018_09_14_15_36_40_912-t.png)

    通过对子区域特征$a_i$做加权，就可以生成一个确定的注意力模型。这样模型更加平滑，并且这种注意力模型下可导，可以用端对端方式使用`BP算法`进行优化。

## 实验

![](http://pics.qiangbenyk.cn/2018_09_14_15_31_50_644-F.png)

第一行为soft-Attention,第二行为hard-attention