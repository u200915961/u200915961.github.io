---
layout: post
title: 'Stacked Attention Networks for Image Question Answering'
subtitle: '利用堆叠注意力模型实现精细图像问答'
date: 2018-09-13
categories: paper
cover: 'http://pics.qiangbenyk.cn/2018_09_13_09_12_23_647-F.png'
tags: Attention object_location deeplearning Image_QA
---

# Stacked Attention Networks for Image Question Answering

## 动机

图像问答任务是结合图像处理和自然语言处理两种技术的任务，通常的解决方案是对图像和文本分别提取深层特征，再结合两个特征，从图像中给出对应问题的回答。但是，这种方案对于图像中细节的回答无法做到很精确。对于下图，图中有很多目标，如果问：“坐在自行车车篮里的是什么？”，对这种问题的回答通常要多次查询图像内容，首先要区分自行车、车篮等目标，再解释''坐''这个动作。

![](http://pics.qiangbenyk.cn/2018_09_13_09_16_33_253-p.png)

## 方法

- 思想

  利用`attention`机制，对卷积提取的特征做挑选，赋予那些与问题相关程度更大的区域特征更高的权重值。这样可以降低无关区域对问题回答的干扰，提升模型性能。经验上讲，对相关区域的确定越精细，生成的回答内容更准确。

- 详细流程

  文章提出的模型氛围三个部分：图像模型，问题模型，和注意力模型。作者使用了一种`stack attention`的技术，使用两层注意力，第一层用于确定目标区域的大致范围，第二层用于进一步筛选区域，提炼更精确的注意力区域。

  - 图像模型

    图像模型可以使用各种常用分类卷积网络，如`VGG`，`ResNet`，`DenseNet`等。本文选用`VGG`作为特征提取器。需要对原始模型做修改，去掉所有的全连接层。`VGG`网络输入$448 \times 448$的三通道图像，最后一层卷积层输出$14 \times 14$的512通道的特征图，$14 \times 14$对应源图像中的196个$32 \times 32$的窗口子区域，每一个$32 \times 32$的区域用512维的特征向量表示。本文用$f_i,i \in [0,195]$表示每一个子区域的特征。

    ![](http://pics.qiangbenyk.cn/2018_09_13_09_30_45_685-a.png)

    再使用一层区域全连接对现有特征加权得到新的特征，新特征表示为$v_I=tanh(W_If_I+b_I)$，其中$v_I$是一个矩阵，表示所有图像子区域的加权特征，形状为$512 \times k$，$k$表示子区域的数目，矩阵的第$i$列表示第$i$个子区域的512维特征。

  - 问题模型

    问题模型用来对文本信息进行特征提取，将文本信息编码为问题向量。本文用了两种问题特征提取方法，分别是基于`LSTM`的问题模型和基于`CNN`的问题模型。

    - 基于LSTM的问题模型

      LSTM使用三个逻辑门(输入门，遗忘门，输出门)控制信息的输入内容，记忆单元的记忆内容，以及输出内容。

      ![](http://pics.qiangbenyk.cn/2018_09_13_09_52_54_259-Z.png)

      给定问题$q=[q_1,q_2,…,q_T]$，其中$q_t$是一个one-hot向量，表示$t$位置的单词。首先对词汇进行编码，将它嵌入到一个向量空间中，新的问题可以编码为$x=[x_1,x_2,…,x_T]$，其中$x_t=W_eq_t$，$W_e$表示嵌入矩阵，这样做的目的是对问题重新编码，原来的one-hot编码方式数据量过大，而且在特征空间上表达不合理。将新的问题编码送入LSTM得到问题特征：

      $x_t=W_eq_t$ ，$t \in \left \{ 1, 2, \cdots, T  \right \}$

      $h_t=LSTM(x_t)$ ，$t \in \left \{ 1, 2, \cdots, T \right \}$

      最后得到问题的特征表示$v_Q=h_T$

    - 基于CNN的问题模型

      同样使用上节介绍的问题编码方法得到最初的问题编码$x$。本文使用三种卷积核，给定尺寸$c$的第$t$个卷积输出表示为$h_{c,t}=tanh(W_cx_{t+c-1}+b_c)$，再对不同的个卷积结果做组合得到三个卷积特征$h_c=[h_{c,1},h_{c,2},…,h_{c,T-c+1}]$，对卷积特征做最大池化：$\widetilde h_c=\underset {t} {max}[h_{c,1},h_{c,2},…,h_{c,T-c+1}]$，最后重组$c$个不同尺寸卷积核的特征，得到最终的问题特征表示$v_Q=h=[\widetilde h_1,\widetilde h_2,\widetilde h_3]$

      ![](http://pics.qiangbenyk.cn/2018_09_13_10_15_24_524-k.png)

  - 注意力模型

    给定图像特征$v_I$和问题特征$v_Q$，首先将他们送入一个有单层神经网络，用softmax函数产生一个图像子区域的注意力分布。

    $h_A=tanh(W_{I,A}v_I \bigoplus (W_{Q,A}v_Q+b_A))$

    $p_I=softmax(W_Ph_A+b_P)$

    其中$v_I \in R^{d \times m}$，$d$图像表示的维度，本文为512；$m$为图像子区域的数目，本文为196。$v_Q \in R^d$是一个$d$维向量。变量分别为$W_{I,A},W_{Q,A} \in R^{k\times d}$，$W_P \in R^{1\times k}$，$p_I \in R^m$。公式中的$\bigoplus$是矩阵和向量的加法，表示矩阵的每一列与向量相加。

    $p_I$表示每个子区域的注意力权重。

    注意力模型是一个小型的两层神经网络，输入为图像特征$v_I$和问题特征$v_P$，分别输入到两个全连接层，这两个全连接层不共享参数，分别得到两个输出，图像特征输出形状为$k\times m$，问题特征输出形状为$1\times k$，将两个特征做矩阵向量加法，得到隐层$h_A$，输出形状为$k \times m$。将隐层输入第二层全连接层，使用softmax激活，输出形状为$1\times m$，分别对应每一个图像子区域特征的权重。

    ![](http://pics.qiangbenyk.cn/2018_09_13_12_55_43_095-B.png)

    对于更复杂的图像问答任务，一层注意力往往不足以做出准确定位，可以增加额外的注意力模型提升注意力的定位精度。

  - stack attention

    假定有第$k$层注意力层为$p_I^k$，通过以下公式得到：

    第$k$层注意力的隐层：$h_A^k=tanh(W_{I,A}^kv_I \bigoplus (W_{Q,A}^ku^{k-1}+b_A^k)$

    第$k$层注意力的权重：$p_I^k=softmax(W_P^kh_A^k+b_P^k)$

    公式中的$u^0$初始值为$v_Q$，即问题特征。聚合的图像特征$\widetilde {v}_I^k$加上原来的问题向量形成新的问题向量。

    $ \widetilde {v}_I^k = \sum _{i}{p_i^k v_i}$

    $u^k = \widetilde {v}_I^k + u^{k-1}$

    每次选中图像区域之后，都会更新问题向量，重复$K$次之后，用最终的问题向量$u^K$推断问题的答案：$p_{ans}=softmax(W_uu^k+b_u)$

## 实验

![](http://pics.qiangbenyk.cn/2018_09_13_13_16_32_082-A.png)

![](http://pics.qiangbenyk.cn/2018_09_13_13_17_05_405-Q.png)

![](http://pics.qiangbenyk.cn/2018_09_13_13_17_31_369-b.png)



































